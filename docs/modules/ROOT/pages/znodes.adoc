= ZNodes

Apache ZooKeeper organizes all data into a hierarchical system of https://zookeeper.apache.org/doc/r3.7.0/zookeeperProgrammers.html#ch_zkDataModel[ZNodes],
which act as both files (they can have data associated with them) and folders (they can contain other ZNodes) when compared to a traditional (POSIX-like) file system.

In order to isolate different clients using the same ZooKeeper cluster, each client application should be assigned a unique root ZNode, which it can then organize
as it sees fit. This can be thought of like a namespace for that client, and prevents clashes between different clients.

The Stackable Operator for Apache ZooKeeper manages ZNodes using the _ZookeeperZnode_ resource. 

[source,yaml]
----
include::example$example-znode.yaml[]
----
<1> The name of the ZNode in ZooKeeper. It is the same as the name of the Kubernetes resource.
<2> Refererence to the `ZookeeperCluster` object where the ZNode should be created.
<3> The namespace of the `ZookeeperCluster`. Can be omitted and will default to the namespace of the ZNode object.

Typically, you would use one ZNode for each client that is using the ZooKeeper instance. Creating this resource will create a ZNode in the referenced ZooKeeper cluster and also create a xref:home:concepts:service_discovery.adoc[discovery ConfigMap] with a xref:discovery.adoc[] for this ZNode. This discovery ConfigMap can then be used in the configuration of the client product to access the specific ZNode created for it. 

The operator _does not_ manage the contents of the ZNode.

CAUTION: The operator automatically deletes the ZNode from the ZooKeeper cluster if the Kubernetes `ZookeeperZnode` object is deleted. Recreating the
`ZookeeperZnode` object will not restore access to the data.

== Split responsibilites for ZooKeeper and ZNodes

One reason for the design of using multiple resources to configure the ZNodes instead of specifying them inside the ZookeeperCluster itself, was to allow different people in an organization to manage them separately.

The ZookeeperCluster might be under the responsibility of a cluster administrator, and access control might prevent anyone from creating or modifying the ZookeeperCluster.

ZNodes however can have different access control and might be configured to be created by a different team which manages product instances using ZooKeeper. Since the ZNode objects are typically used in a one-per-client way, this will allow the people managing the clients to also manage their ZNodes.

== What's next

Have a look at the usage guide for ZNodes: xref:usage_guide:isolating_clients_with_znodes.adoc[]