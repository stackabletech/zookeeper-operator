= Isolating clients with ZNodes

ZooKeeper is a dependency of many products supported by the Stackable Data Platform. To ensure that all products can use the same ZooKeeper cluster safely, it is important to isolate them which is done using xref:ROOT:znodes.adoc[].

This guide shows you how to set up multiple ZNodes to use with different products from the Stackable Data Platform, using Kafka and Druid as an example. For an explanation of the ZNode concept, read the xref:ROOT:znodes.adoc[] concept page.

== Prerequisites

To follow this guide, you should have 

* Access to a Kubernetes cluster
* The Stackable Operator for Apache ZooKeeper installed in said cluster
* A ZookeeperCluster already deployed on the cluster

If you have not yet set up the Operator and ZookeeperCluster, follow the xref:getting_started:index.adoc[getting started guide].

== Steps

This guide assumes the ZookeeperCluster is called `my-zookeeper` and is running in a `data` namespace.

=== Setting up the ZNodes

We want to set up a Kafka and Druid instance to use the ZookeeperCluster, so we will create two ZNodes, one for each product. We will assume the Kafka instance is running in the same namespace as the ZooKeeper, while the Druid instance is running in its own namespace called `druid-ns`.

First, the Druid ZNode:

[source,yaml]
----
include::example$znode/example-znode-druid.yaml[]
----
<1> The name of the Druid ZNode.
<2> The namespace where the ZNode should be created. This should be the same as the namespace of the product or client that wants to use the ZNode.
<3> The ZooKeeper cluster reference. Since ZooKeeper is running in a different namespace, both the cluster name and namespace need to be given.

And the Kafka ZNode:

[source,yaml]
----
include::example$znode/example-znode-kafka.yaml[]
----
<1> The name of the Kafka ZNode.
<2> The namespace where the ZNode should be created. In this case we want Kafka to run in the same namespace as the ZooKeeper cluster.
<3> The ZooKeeper cluster reference. The namespace is omitted here because the ZooKeeper is in the same namespace as the ZNode object.

The Stackable Operator for ZooKeeper watches for ZookeeperZnode objects. If one is found it creates the ZNode _inside_ of the ZooKeeper cluster and also creates a xref:home:concepts:service_discovery.adoc[discovery ConfigMap] in the same namespace as the ZookeeperZnode with the same name as the ZookeeperZnode.

In this example, two ConfigMaps are created:

* The Druid ZNode discovery ConfigMap `druid-znode` in the `druid-ns` namespace
* The Kafka ZNode discovery ConfigMap `kafka-znode` in the `data` namespace

=== Connecting the products to the ZNodes

The ConfigMaps with the name and namespaces as given above will look similar to this:

[source,yaml]
----
include::example$znode/example-znode-discovery.yaml[]
----
<1> Name and namespaces as specified above
<2> `$PATH` will be a unique and unpredictable path that is generated by the operator

This ConfigMap can then be mounted into other Pods and the `ZOOKEEPER` key can be used to connect to the ZooKeeper instance and the correct ZNode.

Across our product resources, the `zookeeperConfigMapName` property is used to give the name of the ZookeeperZnode object, which is then also the name of the ConfigMap.

For Kafka:

[source,yaml]
----
---
apiVersion: kafka.stackable.tech/v1alpha1
kind: DruidCluster
metadata:
  name: my-druid
  namespace: druid-ns
spec:
  zookeeperConfigMapName: kafka-znode
  ...
----

And for Druid:

[source,yaml]
----
---
apiVersion: kafka.stackable.tech/v1alpha1
kind: KafkaCluster
metadata:
  name: my-kafka
  namespace: data
spec:
  zookeeperConfigMapName: kafka-znode
  ...
----

The Stackable Operators for Kafka and Druid will use the discovery ConfigMaps to connect all the Pods in the Kafka and Druid clusters to the ZNode at the shared ZooKeeper cluster.

== What's next

You can find out more about the discovery ConfigMap xref:ROOT:discovery.adoc[] and the xref:ROOT:znodes.adoc[] in the concepts documentation.